#!/usr/bin/env python
"""
Compare Old vs New Ensemble Quantile Files

This script compares quantile files generated by different processing runs
to verify consistency and identify any differences.

Old files location: /mnt/CEPH_PROJECTS/FACT_CLIMAX/tmp_data_Firescape/{var}/{scenario}/
New files location: /mnt/CEPH_PROJECTS/FACT_CLIMAX/tmp_data_Firescape/climate_projections_ensemble_quantiles/{var_name}/{scenario}/
"""

import xarray as xr
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings("ignore")

# ===================================================================
# CONFIGURATION
# ===================================================================

OLD_BASE_DIR = Path("/mnt/CEPH_PROJECTS/FACT_CLIMAX/tmp_data_Firescape")
NEW_BASE_DIR = Path(
    "/mnt/CEPH_PROJECTS/FACT_CLIMAX/tmp_data_Firescape/climate_projections_ensemble_quantiles"
)

# Map variable codes to directory names
VAR_MAPPING = {
    "tas": ("tas", "temperature"),
    "pr": ("pr", "precipitation"),
}

SCENARIOS = ["rcp45", "rcp85"]
QUANTILES = [25, 50, 75, 99]

OUTPUT_DIR = Path("/mnt/CEPH_PROJECTS/Firescape/output/01_Data_Preparation")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


# ===================================================================
# COMPARISON FUNCTIONS
# ===================================================================


def compare_netcdf_files(old_file, new_file, var_code):
    """
    Compare two NetCDF files and return comparison statistics.
    """
    results = {
        "old_exists": old_file.exists(),
        "new_exists": new_file.exists(),
        "old_file": str(old_file),
        "new_file": str(new_file),
    }

    if not results["old_exists"]:
        results["status"] = "OLD_MISSING"
        return results

    if not results["new_exists"]:
        results["status"] = "NEW_MISSING"
        return results

    try:
        # Open both files
        ds_old = xr.open_dataset(old_file)
        ds_new = xr.open_dataset(new_file)

        # Get the data variable
        data_old = ds_old[var_code]
        data_new = ds_new[var_code]

        # File sizes
        results["old_size_gb"] = old_file.stat().st_size / (1024**3)
        results["new_size_gb"] = new_file.stat().st_size / (1024**3)

        # Dimensions
        results["old_shape"] = dict(data_old.sizes)
        results["new_shape"] = dict(data_new.sizes)

        # Check if dimensions match
        if data_old.shape != data_new.shape:
            results["status"] = "SHAPE_MISMATCH"
            ds_old.close()
            ds_new.close()
            return results

        # Time range comparison
        results["old_time_range"] = (
            str(data_old.time.values[0])[:10],
            str(data_old.time.values[-1])[:10],
        )
        results["new_time_range"] = (
            str(data_new.time.values[0])[:10],
            str(data_new.time.values[-1])[:10],
        )

        # Statistical comparison (using a sample to avoid memory issues)
        # Sample every 100th time step
        sample_old = data_old.isel(time=slice(0, None, 100)).values
        sample_new = data_new.isel(time=slice(0, None, 100)).values

        # Remove NaN values for comparison
        valid_mask = ~(np.isnan(sample_old) | np.isnan(sample_new))
        sample_old_valid = sample_old[valid_mask]
        sample_new_valid = sample_new[valid_mask]

        if len(sample_old_valid) > 0:
            # Calculate differences
            diff = sample_new_valid - sample_old_valid
            abs_diff = np.abs(diff)
            rel_diff = abs_diff / (np.abs(sample_old_valid) + 1e-10) * 100

            results["mean_old"] = float(np.mean(sample_old_valid))
            results["mean_new"] = float(np.mean(sample_new_valid))
            results["mean_abs_diff"] = float(np.mean(abs_diff))
            results["max_abs_diff"] = float(np.max(abs_diff))
            results["mean_rel_diff_pct"] = float(np.mean(rel_diff))
            results["max_rel_diff_pct"] = float(np.max(rel_diff))
            results["correlation"] = float(np.corrcoef(sample_old_valid, sample_new_valid)[0, 1])
            results["rmse"] = float(np.sqrt(np.mean(diff**2)))

            # Determine status
            if results["mean_abs_diff"] < 1e-6:
                results["status"] = "IDENTICAL"
            elif results["mean_rel_diff_pct"] < 0.01:
                results["status"] = "VERY_SIMILAR"
            elif results["mean_rel_diff_pct"] < 1.0:
                results["status"] = "SIMILAR"
            else:
                results["status"] = "DIFFERENT"
        else:
            results["status"] = "NO_VALID_DATA"

        ds_old.close()
        ds_new.close()

    except Exception as e:
        results["status"] = "ERROR"
        results["error"] = str(e)

    return results


def print_comparison_report(all_results):
    """
    Print a formatted comparison report.
    """
    print("\n" + "=" * 80)
    print("ENSEMBLE QUANTILE FILES COMPARISON REPORT")
    print("=" * 80)

    for var_code, var_results in all_results.items():
        var_code_orig, var_name = VAR_MAPPING[var_code]
        print(f"\n{var_name.upper()} ({var_code})")
        print("-" * 80)

        for scenario, scenario_results in var_results.items():
            print(f"\n  Scenario: {scenario.upper()}")

            for pctl, result in scenario_results.items():
                status = result.get("status", "UNKNOWN")
                print(f"\n    pctl{pctl}: {status}")

                if status == "OLD_MISSING":
                    print(f"      ✗ Old file not found: {result['old_file']}")
                elif status == "NEW_MISSING":
                    print(f"      ✗ New file not found: {result['new_file']}")
                elif status == "ERROR":
                    print(f"      ✗ Error: {result.get('error', 'Unknown error')}")
                elif status in ["IDENTICAL", "VERY_SIMILAR", "SIMILAR", "DIFFERENT"]:
                    print(f"      Old size: {result['old_size_gb']:.2f} GB")
                    print(f"      New size: {result['new_size_gb']:.2f} GB")
                    print(f"      Shape: {result['old_shape']}")
                    print(f"      Time range (old): {result['old_time_range'][0]} to {result['old_time_range'][1]}")
                    print(f"      Time range (new): {result['new_time_range'][0]} to {result['new_time_range'][1]}")

                    if "mean_abs_diff" in result:
                        print(f"      Mean absolute difference: {result['mean_abs_diff']:.6f}")
                        print(f"      Max absolute difference: {result['max_abs_diff']:.6f}")
                        print(f"      Mean relative difference: {result['mean_rel_diff_pct']:.4f}%")
                        print(f"      RMSE: {result['rmse']:.6f}")
                        print(f"      Correlation: {result['correlation']:.6f}")


def save_comparison_summary(all_results, output_file):
    """
    Save comparison summary to a text file.
    """
    with open(output_file, "w") as f:
        f.write("Ensemble Quantile Files Comparison Summary\n")
        f.write("=" * 80 + "\n\n")

        summary = {"IDENTICAL": 0, "VERY_SIMILAR": 0, "SIMILAR": 0, "DIFFERENT": 0,
                   "OLD_MISSING": 0, "NEW_MISSING": 0, "ERROR": 0}

        for var_code, var_results in all_results.items():
            for scenario, scenario_results in var_results.items():
                for pctl, result in scenario_results.items():
                    status = result.get("status", "ERROR")
                    summary[status] = summary.get(status, 0) + 1

                    f.write(f"{var_code}/{scenario}/pctl{pctl}: {status}\n")
                    if status in ["IDENTICAL", "VERY_SIMILAR", "SIMILAR", "DIFFERENT"]:
                        if "mean_rel_diff_pct" in result:
                            f.write(f"  Mean rel diff: {result['mean_rel_diff_pct']:.4f}%\n")
                            f.write(f"  Correlation: {result['correlation']:.6f}\n")

        f.write("\n" + "=" * 80 + "\n")
        f.write("Summary Statistics:\n")
        for status, count in summary.items():
            if count > 0:
                f.write(f"  {status}: {count}\n")

    print(f"\nComparison summary saved to: {output_file}")


# ===================================================================
# MAIN FUNCTION
# ===================================================================


def main():
    """
    Main comparison function.
    """
    print("Starting ensemble quantile comparison...")
    print(f"Old files: {OLD_BASE_DIR}")
    print(f"New files: {NEW_BASE_DIR}")

    all_results = {}

    for var_code, (var_code_orig, var_name) in VAR_MAPPING.items():
        all_results[var_code] = {}

        for scenario in SCENARIOS:
            all_results[var_code][scenario] = {}

            for pctl in QUANTILES:
                # Construct file paths
                old_file = (
                    OLD_BASE_DIR / var_code_orig / scenario /
                    f"{var_code}_EUR-11_pctl{pctl}_{scenario}.nc"
                )
                new_file = (
                    NEW_BASE_DIR / var_name / scenario /
                    f"{var_code}_EUR-11_pctl{pctl}_{scenario}.nc"
                )

                print(f"\nComparing {var_code}/{scenario}/pctl{pctl}...")
                result = compare_netcdf_files(old_file, new_file, var_code)
                all_results[var_code][scenario][pctl] = result

    # Print report
    print_comparison_report(all_results)

    # Save summary
    summary_file = OUTPUT_DIR / "quantile_comparison_summary.txt"
    save_comparison_summary(all_results, summary_file)

    print("\n" + "=" * 80)
    print("COMPARISON COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    main()
